{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os, sys, string\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('valid_words.pickle', 'rb') as f:\n",
    "    valid_words = pickle.load(f)\n",
    "exclude = set(string.punctuation)\n",
    "raw_texts = open('CPRFD10.TXT', encoding='utf-8').read()\n",
    "raw_texts = raw_texts.strip().lower()\n",
    "raw_texts = ''.join(ch for ch in raw_texts if ch not in exclude and type(ch) != 'str')\n",
    "raw_words = nltk.word_tokenize(raw_texts)\n",
    "raw_words = [w if w in valid_words else 'UNK' for w in raw_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 4476\n",
      "4461\n"
     ]
    }
   ],
   "source": [
    "words = sorted(list(set(raw_words)))\n",
    "word_to_index = {w: i+1 for i, w in enumerate(words)}\n",
    "index_to_word = {i+1: w for i, w in enumerate(words)}\n",
    "\n",
    "n_vocab = len(words)+1\n",
    "print('Total number of words:', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 356178\n"
     ]
    }
   ],
   "source": [
    "sent_len = 10\n",
    "dataX, dataY = [], []\n",
    "for i in range(len(raw_words) - sent_len):\n",
    "    dataX.append([word_to_index[w] for w in raw_words[i:i+sent_len]])\n",
    "    dataY.append(word_to_index[raw_words[i+sent_len]])\n",
    "n_patterns = len(dataX)\n",
    "print('Total Patterns:', n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, sent_len, 1))\n",
    "X = X/float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2 layer stacked LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1024, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(1024))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "filename = \"weights-improvement-49-0.2259.hdf5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testingX, options, testingY = [], [], []\n",
    "with open('parsed_testing_data.csv', 'r') as f:\n",
    "    firstTime = True\n",
    "    for line in f:\n",
    "        if firstTime:\n",
    "            firstTime = False\n",
    "            continue\n",
    "        tokens = line.strip().split('\\t')\n",
    "        X = tokens[0][1:-1].split(',')\n",
    "        option = tokens[1:-1]\n",
    "        Y = ord(tokens[-1])-ord('a')\n",
    "        X = [word_to_index[w.strip()[1:-1]] for w in X]\n",
    "        testingX.append(X)\n",
    "        options.append(option)\n",
    "        testingY.append(Y)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pick a random seed\n",
    "predictions = []\n",
    "for i, test in enumerate(testingX):\n",
    "    option = options[i]\n",
    "    option = [word_to_index[w] if w in valid_words else word_to_index['UNK'] for w in option]\n",
    "    x = np.reshape(test, (1, len(test), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    ops = np.array([prediction[0,i] for i in option])\n",
    "    predict_ans = np.argmax(ops)\n",
    "    predictions.append(predict_ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17307692307692307"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x,y in zip(predictions,testingY) if x == y) / len(testingY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
